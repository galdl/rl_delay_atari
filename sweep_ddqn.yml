program: run_experiment_rl_delay.py
method: grid
metric:
  goal: minimize
  name: episodic_reward
parameters:
  env_name:
    values: ['MsPacmanNoFrameskip-v4'] #['MsPacman-v0']
  augment_state:
    values: [False]
  delay_value:
    values: [5]
  train_freq:
    values: [4]
  exploration_initial_eps:
    values: [1.0]
  learning_rate:
    values: [0.0001]
  target_network_update_freq:
    values: [1000]
  exploration_final_eps:
    values: [0.001]
  buffer_size:
    values: [25000]
  seed:
    values: [1]
  prioritized_replay:
    values: [True]
  fixed_frame_skip:
    values: [True]
  clone_full_state:
    values: [False]
  load_pretrained_agent:
    values: [False]
  pix2pix_lr:
    values: [0.0002]
  pix2pix_beta1:
    values: [0.1, 0.5, 0.9]
  pix2pix_l1_weight:
    values: [100.0, 50.0, 1.0]
  pix2pix_gan_weight:
    values: [100.0, 50.0, 1.0]
  use_learned_forward_model:
    values: [True]
