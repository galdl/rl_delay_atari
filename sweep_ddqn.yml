program: run_experiment_rl_delay.py
method: grid
metric:
  goal: maximize
  name: episodic_reward
parameters:
  seed:
    values: [1, 2, 3, 4, 5]
  total_timesteps:
    values: [1000000]
  deepmind_wrapper:
    values: [False]
  env_name:
    values: ['EnduroNoFrameskip-v4', 'AlienNoFrameskip-v4', 'QbertNoFrameskip-v4']
  agent_type:
    values: ['delayed', 'augmented', 'oblivious'] # rnn
  delay_value:
    values:  [0, 5, 15, 25]
  train_freq:
    values: [4]
  exploration_initial_eps:
    values: [1.0]
  learning_rate:
    values: [0.0001]
  target_network_update_freq:
    values: [1000]
  exploration_final_eps:
    values: [0.001]
  buffer_size:
    values: [25000]
  prioritized_replay:
    values: [False]
  fixed_frame_skip:
    values: [True]
  clone_full_state:
    values: [False]
  load_pretrained_agent:
    values: [False]


